#!/usr/bin/env python3
"""
ä½¿ç”¨ç§æœ‰ Hugging Face Space çš„ç¤ºä¾‹ä»£ç 
"""

import requests
import json
import os

# é…ç½®
SPACE_URL = "https://your-username-your-spacename.hf.space"  # æ›¿æ¢ä¸ºä½ çš„ç©ºé—´URL
HF_TOKEN = "your_hf_token_here"  # æ›¿æ¢ä¸ºä½ çš„ HF Token
# æˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰ API Key
# API_KEY = "your_api_key_here"

def chat_with_gemini(message: str, token: str) -> str:
    """
    ä¸ Gemini èŠå¤©
    
    Args:
        message: è¦å‘é€çš„æ¶ˆæ¯
        token: è®¤è¯ä»¤ç‰Œ (HF_TOKEN æˆ– API_KEY)
    
    Returns:
        Gemini çš„å›å¤
    """
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "gemini-2.0-flash",
        "messages": [
            {
                "role": "user",
                "content": message
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1000
    }
    
    try:
        response = requests.post(
            f"{SPACE_URL}/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            return f"Error: {response.status_code} - {response.text}"
            
    except Exception as e:
        return f"Exception: {str(e)}"

def stream_chat_with_gemini(message: str, token: str):
    """
    æµå¼èŠå¤©ç¤ºä¾‹
    
    Args:
        message: è¦å‘é€çš„æ¶ˆæ¯
        token: è®¤è¯ä»¤ç‰Œ
    """
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "gemini-2.0-flash",
        "messages": [
            {
                "role": "user",
                "content": message
            }
        ],
        "temperature": 0.7,
        "stream": True
    }
    
    try:
        response = requests.post(
            f"{SPACE_URL}/v1/chat/completions",
            headers=headers,
            json=data,
            stream=True,
            timeout=30
        )
        
        if response.status_code == 200:
            print("ğŸ¤– Gemini (streaming): ", end="", flush=True)
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith('data: '):
                        data_str = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                        if data_str.strip() == '[DONE]':
                            break
                        try:
                            data = json.loads(data_str)
                            if 'choices' in data and len(data['choices']) > 0:
                                delta = data['choices'][0].get('delta', {})
                                if 'content' in delta:
                                    print(delta['content'], end="", flush=True)
                        except json.JSONDecodeError:
                            continue
            print()  # æ¢è¡Œ
        else:
            print(f"Error: {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"Exception: {str(e)}")

def get_available_models(token: str) -> list:
    """
    è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    Args:
        token: è®¤è¯ä»¤ç‰Œ
    
    Returns:
        æ¨¡å‹åˆ—è¡¨
    """
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(
            f"{SPACE_URL}/v1/models",
            headers=headers,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            return [model['id'] for model in result.get('data', [])]
        else:
            print(f"Error getting models: {response.status_code} - {response.text}")
            return []
            
    except Exception as e:
        print(f"Exception getting models: {str(e)}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–ä»¤ç‰Œ
    token = os.getenv("HF_TOKEN") or os.getenv("API_KEY")
    
    if not token:
        print("è¯·è®¾ç½® HF_TOKEN æˆ– API_KEY ç¯å¢ƒå˜é‡")
        print("æˆ–è€…ç›´æ¥åœ¨ä»£ç ä¸­ä¿®æ”¹ HF_TOKEN æˆ– API_KEY å˜é‡")
        return
    
    print("ğŸš€ ç§æœ‰ Hugging Face Space ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # è·å–å¯ç”¨æ¨¡å‹
    print("ğŸ“‹ è·å–å¯ç”¨æ¨¡å‹...")
    models = get_available_models(token)
    if models:
        print(f"âœ… æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹:")
        for model in models[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"   - {model}")
    else:
        print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
        return
    
    # æ™®é€šèŠå¤©ç¤ºä¾‹
    print("\nğŸ’¬ æ™®é€šèŠå¤©ç¤ºä¾‹:")
    message = "ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡å›å¤ã€‚"
    print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
    
    response = chat_with_gemini(message, token)
    print(f"ğŸ¤– Gemini: {response}")
    
    # æµå¼èŠå¤©ç¤ºä¾‹
    print("\nğŸŒŠ æµå¼èŠå¤©ç¤ºä¾‹:")
    message = "è¯·å†™ä¸€é¦–å…³äºäººå·¥æ™ºèƒ½çš„çŸ­è¯—ã€‚"
    print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
    
    stream_chat_with_gemini(message, token)
    
    print("\nâœ¨ ç¤ºä¾‹å®Œæˆï¼")

if __name__ == "__main__":
    main()
